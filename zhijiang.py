import requests
import json
import os
import time
from loguru import logger
from datetime import datetime, timedelta
from collections import defaultdict

# é…ç½®å‚æ•°
max_attempts = 10
# æ”¯æŒå¤šä¸ªäººå‘˜æŸ¥è¯¢
names = ["å”ä¸½", "å‘¨æ°‘é”‹", "æœ±é™ˆè¶…", "é»„æ­£æ˜"]
BASE_url = "http://106.15.60.27:33333"
login_url = "http://106.15.60.27:33333/laboratt/attendance/page"
wexinqq_url = "https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=fc744023-75ec-420d-95d1-d9c896117c29"

# ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯é•¿åº¦é™åˆ¶ (4096å­—ç¬¦)
MAX_MESSAGE_LENGTH = 2000  # ä¿ç•™ä¸€äº›ç©ºé—´

# å·¥ä½œæ—¶é•¿é˜ˆå€¼ (å°æ—¶)
WORK_DURATION_THRESHOLD = 4

headers = {
    "Connection": "keep-alive",
    "sec-ch-ua": '"Not.A/Brand";v="8", "Chromium";v="114"',
    "Accept": "*/*",
    "Content-Type": "application/json;charset=UTF-8",
    "sec-ch-ua-mobile": "?0",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.289 Safari/537.36",
    "sec-ch-ua-platform": '"Windows"',
    "Origin": "http://106.15.60.27:33333",
    "Referer": "http://106.15.60.27:33333/login/",
    "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8,vi;q=0.7",
    "Accept-Encoding": "gzip, deflate",
    "Authorization": "Basic cGlnOnBpZw=="
}

# ================== é€šçŸ¥å‘é€ ==================
def send_wexinqq_md(content):
    """å‘é€Markdownæ¶ˆæ¯åˆ°ä¼ä¸šå¾®ä¿¡"""
    try:
        # æ£€æŸ¥å†…å®¹é•¿åº¦
        if len(content) > MAX_MESSAGE_LENGTH:
            logger.warning(f"æ¶ˆæ¯é•¿åº¦ {len(content)} è¶…è¿‡é™åˆ¶ ({MAX_MESSAGE_LENGTH})ï¼Œå°†è¢«æˆªæ–­")
            content = content[:MAX_MESSAGE_LENGTH] + "\n\n...ï¼ˆå†…å®¹è¿‡é•¿è¢«æˆªæ–­ï¼‰"
        
        response = requests.post(
            wexinqq_url,
            json={'msgtype': 'markdown', 'markdown': {'content': content}},
            timeout=10
        )
        result = response.json()
        if result.get('errcode') == 0:
            logger.success("ä¼ä¸šå¾®ä¿¡é€šçŸ¥å‘é€æˆåŠŸ")
            return True
        else:
            logger.error(f"ä¼ä¸šå¾®ä¿¡é€šçŸ¥å‘é€å¤±è´¥: {result}")
            return False
    except Exception as e:
        logger.error(f"å‘é€ä¼ä¸šå¾®ä¿¡é€šçŸ¥æ—¶å‡ºé”™: {str(e)}")
        return False

def send_paginated_messages(messages):
    """åˆ†é¡µå‘é€æ¶ˆæ¯ï¼Œé¿å…è¶…è¿‡é•¿åº¦é™åˆ¶"""
    if not messages:
        return False
    
    # è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„å¹³å‡é•¿åº¦
    total_length = sum(len(msg) for msg in messages)
    if messages:
        avg_length = total_length / len(messages)
    else:
        avg_length = 0
    
    # è®¡ç®—æ¯æ‰¹å¯ä»¥åŒ…å«å¤šå°‘æ¡æ¶ˆæ¯
    if avg_length > 0:
        batch_size = max(1, int(MAX_MESSAGE_LENGTH / avg_length))
    else:
        batch_size = 5  # é»˜è®¤æ¯æ‰¹5æ¡
    
    logger.info(f"å¹³å‡æ¯æ¡æ¶ˆæ¯é•¿åº¦: {avg_length:.0f}, æ¯æ‰¹å‘é€ {batch_size} æ¡è®°å½•")
    
    # åˆ†æ‰¹å‘é€
    all_success = True
    for i in range(0, len(messages), batch_size):
        batch = messages[i:i + batch_size]
        content = "\n\n".join(batch)
        
        # æ·»åŠ åˆ†é¡µä¿¡æ¯
        total_pages = (len(messages) + batch_size - 1) // batch_size
        current_page = i // batch_size + 1
        page_info = f"# ğŸ“‹ è€ƒå‹¤è®°å½•é€šçŸ¥ ({current_page}/{total_pages})\n\n"
        
        # å‘é€å½“å‰æ‰¹æ¬¡
        logger.info(f"å‘é€ç¬¬ {current_page}/{total_pages} æ‰¹æ¶ˆæ¯ ({len(batch)}æ¡è®°å½•)")
        if not send_wexinqq_md(page_info + content):
            all_success = False
            logger.error(f"ç¬¬ {current_page} æ‰¹æ¶ˆæ¯å‘é€å¤±è´¥")
        
        # æ‰¹æ¬¡é—´å»¶è¿Ÿ
        time.sleep(1)
    
    return all_success

# ================== æ•°æ®ç›‘æ§ ==================
def load_existing_ids():
    """åŠ è½½å·²è®°å½•çš„IDé›†åˆ"""
    try:
        if os.path.exists('zjids.json'):
            with open('zjids.json') as f:
                ids = json.load(f)
                logger.info(f"æˆåŠŸåŠ è½½ {len(ids)} æ¡å†å²è®°å½•ID")
                return set(ids)
        else:
            logger.warning("æœªæ‰¾åˆ°zjids.jsonæ–‡ä»¶ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
            return set()
    except json.JSONDecodeError:
        logger.error("zjids.jsonæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œå°†é‡æ–°åˆ›å»º")
        return set()

def save_new_ids(ids):
    """ä¿å­˜æ–°çš„IDé›†åˆ"""
    try:
        with open('zjids.json', 'w') as f:
            json.dump(list(ids), f)
        logger.info(f"æˆåŠŸä¿å­˜{len(ids)}æ¡è®°å½•IDåˆ°zjids.json")
    except Exception as e:
        logger.error(f"ä¿å­˜IDé›†åˆå¤±è´¥: {str(e)}")

def fetch_records_for_name(name):
    """è·å–å•ä¸ªåå­—çš„ç¬¬ä¸€é¡µæ•°æ®"""
    try:
        # æ„å»ºæŸ¥è¯¢URL
        url = f"{login_url}?page=1&limit=10&name={name}&orderByField=verifyTime&isAsc=false"
        logger.debug(f"è¯·æ±‚URL: {url}")
        
        response = requests.get(url, headers=headers, timeout=60)
        logger.info(f"è¯·æ±‚ {name} çš„è€ƒå‹¤è®°å½•, çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code != 200:
            logger.error(f"è¯·æ±‚å¤±è´¥: {response.text}")
            return []

        json_data = response.json()

        # å…¼å®¹å¤„ç†ä¸åŒç»“æ„
        if "data" in json_data and isinstance(json_data["data"], dict):
            records = json_data["data"].get("records", [])
        elif "records" in json_data and isinstance(json_data["records"], list):
            records = json_data["records"]
        else:
            logger.error(f"å“åº”æ ¼å¼å¼‚å¸¸: {json_data}")
            return []

        logger.info(f"è·å–åˆ° {name} çš„ {len(records)} æ¡è®°å½•")
        return records
        
    except Exception as e:
        logger.error(f"è·å–æ•°æ®å¤±è´¥: {e}")
        return []

def fetch_all_records():
    """è·å–æ‰€æœ‰åå­—çš„æ‰€æœ‰è®°å½•"""
    all_records = []
    for name in names:
        logger.info(f"å¼€å§‹æŸ¥è¯¢ {name} çš„è€ƒå‹¤è®°å½•")
        records = fetch_records_for_name(name)
        all_records.extend(records)
        logger.success(f"æŸ¥è¯¢åˆ° {name} çš„ {len(records)} æ¡è®°å½•")
    
    # æŒ‰æ—¶é—´æ’åº (ä»æ–°åˆ°æ—§)
    all_records.sort(key=lambda x: x.get('verifyTime', 0), reverse=True)
    return all_records

def process_records(records):
    """å¤„ç†è®°å½•ï¼Œæ·»åŠ åŒ—äº¬æ—¶é—´"""
    processed_records = []
    
    for record in records:
        timestamp = record.get('verifyTime', 0) / 1000
        if timestamp:
            utc_time = datetime.utcfromtimestamp(timestamp)
            beijing_time = utc_time + timedelta(hours=8)
            record['beijing_time'] = beijing_time
            record['date_key'] = beijing_time.date().isoformat()
        else:
            record['beijing_time'] = None
            record['date_key'] = 'unknown'
        
        processed_records.append(record)
    
    return processed_records

def calculate_daily_work_durations(processed_records):
    """è®¡ç®—æ¯ä¸ªäººæ¯å¤©çš„å·¥ä½œæ—¶é•¿"""
    daily_work_durations = {}
    daily_records = defaultdict(lambda: defaultdict(list))
    
    # æŒ‰å§“åå’Œæ—¥æœŸåˆ†ç»„è®°å½•
    for record in processed_records:
        name = record.get('name', 'æœªçŸ¥')
        date_key = record.get('date_key')
        status = record.get('inOrOut', 'unknown')
        beijing_time = record.get('beijing_time')
        
        if name != 'æœªçŸ¥' and date_key != 'unknown' and beijing_time:
            daily_records[(name, date_key)][status].append(beijing_time)
    
    # è®¡ç®—æ¯å¤©çš„å·¥ä½œæ—¶é•¿
    for (name, date_key), records_by_status in daily_records.items():
        in_times = records_by_status.get('in', [])
        out_times = records_by_status.get('out', [])
        
        if in_times and out_times:
            # æ‰¾åˆ°æœ€æ—©çš„è¿›å…¥æ—¶é—´
            earliest_in = min(in_times)
            # æ‰¾åˆ°æœ€æ™šçš„ç¦»å¼€æ—¶é—´
            latest_out = max(out_times)
            
            # ç¡®ä¿ç¦»å¼€æ—¶é—´åœ¨è¿›å…¥æ—¶é—´ä¹‹å
            if latest_out > earliest_in:
                # è®¡ç®—å·¥ä½œæ—¶é•¿ï¼ˆå°æ—¶ï¼‰
                work_duration = (latest_out - earliest_in).total_seconds() / 3600
                
                # è®°å½•å·¥ä½œæ—¶é•¿
                daily_work_durations[(name, date_key)] = work_duration
                
                logger.info(f"{name} åœ¨ {date_key} çš„å·¥ä½œæ—¶é•¿: {work_duration:.2f}å°æ—¶")
                logger.info(f"  æœ€æ—©è¿›å…¥: {earliest_in.strftime('%H:%M:%S')}")
                logger.info(f"  æœ€æ™šç¦»å¼€: {latest_out.strftime('%H:%M:%S')}")
            else:
                logger.warning(f"{name} åœ¨ {date_key} çš„ç¦»å¼€æ—¶é—´æ—©äºè¿›å…¥æ—¶é—´ï¼Œä¸è®¡ç®—å·¥ä½œæ—¶é•¿")
        else:
            logger.info(f"{name} åœ¨ {date_key} ç¼ºå°‘è¿›å‡ºè®°å½•ï¼Œæ— æ³•è®¡ç®—å·¥ä½œæ—¶é•¿")
    
    return daily_work_durations

def check_new_records():
    """æ£€æŸ¥æ–°è®°å½•å¹¶å‘é€é€šçŸ¥"""
    try:
        existing_ids = load_existing_ids()
        logger.info(f"å·²åŠ è½½ {len(existing_ids)} æ¡å†å²è®°å½•ID")
        
        current_ids = set()
        new_records = []
        
        records = fetch_all_records()
        logger.info(f"æ€»å…±æŸ¥è¯¢åˆ° {len(records)} æ¡è®°å½•")
        
        # æ£€æŸ¥æ–°è®°å½•
        for record in records:
            record_id = record.get('id')
            if not record_id:
                continue
                
            current_ids.add(record_id)
            if record_id not in existing_ids:
                new_records.append(record)
        
        if new_records:
            logger.success(f"å‘ç° {len(new_records)} æ¡æ–°è®°å½•")
            
            # æŒ‰æ—¶é—´æ’åº (ä»æ—§åˆ°æ–°ï¼Œè¿™æ ·é€šçŸ¥ä¸­å…ˆæ˜¾ç¤ºæœ€æ—©çš„è®°å½•)
            new_records.sort(key=lambda x: x.get('verifyTime', 0))
            
            # å¤„ç†è®°å½•ï¼Œæ·»åŠ åŒ—äº¬æ—¶é—´
            processed_records = process_records(new_records)
            
            # è®¡ç®—æ¯æ—¥å·¥ä½œæ—¶é•¿
            daily_work_durations = calculate_daily_work_durations(processed_records)
            
            messages = []
            warning_dates = []
            warnings_by_date = {}
            
            # æ£€æŸ¥å“ªäº›æ—¥æœŸçš„å·¥ä½œæ—¶é•¿ä¸è¶³
            for (name, date_key), duration in daily_work_durations.items():
                if duration < WORK_DURATION_THRESHOLD:
                    warning_dates.append((name, date_key))
                    warnings_by_date[(name, date_key)] = {
                        'duration': duration,
                        'name': name,
                        'date': date_key
                    }
                    logger.warning(f"{name} åœ¨ {date_key} çš„å·¥ä½œæ—¶é•¿ä¸è¶³: {duration:.2f}å°æ—¶ (< {WORK_DURATION_THRESHOLD}å°æ—¶)")
            
            # ä¸ºæ¯æ¡è®°å½•åˆ›å»ºæ¶ˆæ¯
            for record in processed_records:
                beijing_time = record.get('beijing_time')
                time_str = beijing_time.strftime('%Y-%m-%d %H:%M:%S') if beijing_time else "æœªçŸ¥æ—¶é—´"
                
                # è·å–é¡¹ç›®åç§°
                project_name = record.get('engName', 'æœªçŸ¥é¡¹ç›®')
                if not project_name or project_name == 'null':
                    project_name = record.get('projectName', 'æœªçŸ¥é¡¹ç›®')
                
                # è·å–è¿›å‡ºçŠ¶æ€
                status = record.get('inOrOut', 'æœªçŸ¥')
                status_text = "è¿›å…¥" if status == 'in' else "ç¦»å¼€"
                status_color = "info" if status == 'in' else "warning"
                
                # åˆ›å»ºæ¶ˆæ¯
                message = (
                    f"## ğŸ‰ æ–°è€ƒå‹¤è®°å½•\n"
                    f"> **é¡¹ç›®åç§°**: {project_name}\n"
                    f"> **å§“å**: {record.get('name', 'æœªçŸ¥')}\n"
                    f"> **å²—ä½**: {record.get('jobName', 'æœªçŸ¥')}\n"
                    f"> **æ—¶é—´**: <font color=\"info\">{time_str}</font>\n"
                    f"> **çŠ¶æ€**: <font color=\"{status_color}\">{status_text}</font>\n"
                )
                
                # å¯¹äºç¦»å¼€è®°å½•ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…³è”çš„æ—¥æœŸéœ€è¦è­¦å‘Š
                name = record.get('name', 'æœªçŸ¥')
                date_key = record.get('date_key')
                
                # åªæœ‰åœ¨ç¦»å¼€è®°å½•ä¸”è¯¥æ—¥æœŸæœ‰å·¥ä½œæ—¶é•¿è®¡ç®—æ—¶æ‰æ˜¾ç¤º
                if status == 'out' and name != 'æœªçŸ¥' and date_key != 'unknown' and beijing_time:
                    if (name, date_key) in warnings_by_date:
                        duration = warnings_by_date[(name, date_key)]['duration']
                        message += f"> **å½“å¤©å·¥ä½œæ—¶é•¿**: {duration:.2f}å°æ—¶\n"
                        message += f"> **è­¦å‘Š**: <font color=\"warning\">å·¥ä½œæ—¶é•¿ä¸è¶³{WORK_DURATION_THRESHOLD}å°æ—¶ï¼</font>\n"
                    elif (name, date_key) in daily_work_durations:
                        # å¦‚æœå·¥ä½œæ—¶é•¿æ­£å¸¸ï¼Œä¹Ÿå¯ä»¥æ˜¾ç¤ºï¼ˆå¯é€‰ï¼‰
                        duration = daily_work_durations.get((name, date_key))
                        if duration:
                            message += f"> **å½“å¤©å·¥ä½œæ—¶é•¿**: {duration:.2f}å°æ—¶\n"
                
                messages.append(message)
            
            # æ·»åŠ æ€»æ ‡é¢˜
            summary = f"# ğŸ“¢ å‘ç° {len(new_records)} æ¡æ–°è€ƒå‹¤è®°å½•\n"
            if warning_dates:
                summary += f"## âš ï¸ å…¶ä¸­æœ‰ {len(warning_dates)} å¤©çš„å·¥ä½œæ—¶é•¿ä¸è¶³{WORK_DURATION_THRESHOLD}å°æ—¶\n"
                # æŒ‰å§“ååˆ†ç»„æ˜¾ç¤ºè­¦å‘Š
                warnings_by_name = defaultdict(list)
                for name, date_key in warning_dates:
                    duration = daily_work_durations.get((name, date_key), 0)
                    warnings_by_name[name].append((date_key, duration))
                
                for name, date_list in warnings_by_name.items():
                    for date_key, duration in date_list:
                        summary += f"> **{name}** åœ¨ **{date_key}** çš„å·¥ä½œæ—¶é•¿: {duration:.2f}å°æ—¶\n"
                summary += "\n"
            
            # åˆ†é¡µå‘é€æ¶ˆæ¯
            message_list = [summary] + messages
            send_success = send_paginated_messages(message_list)
            
            # é€šçŸ¥å‘é€æˆåŠŸåæ‰ä¿å­˜ID
            if send_success:
                save_new_ids(existing_ids.union(current_ids))
                return True
            else:
                logger.error("é€šçŸ¥å‘é€å¤±è´¥ï¼Œä¸æ›´æ–°è®°å½•ID")
                return False
        else:
            logger.info("æœªå‘ç°æ–°è®°å½•")
            return False
            
    except Exception as e:
        logger.error(f"æ£€æŸ¥æ–°è®°å½•æ—¶å‡ºé”™: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False

# ================== ä¸»å¾ªç¯ ==================
def main():
    try:
        # æ•°æ®æ£€æŸ¥
        if check_new_records():
            logger.success("å‘ç°æ–°è®°å½•å¹¶æˆåŠŸé€šçŸ¥")
        else:
            logger.info("æœªå‘ç°æ–°è®°å½•")
        
        # ä¸€æ¬¡æ€§æ‰§è¡Œåç»“æŸç¨‹åºï¼Œä¸å†å¾ªç¯
        logger.info("æ‰§è¡Œå®Œæ¯•ï¼Œç¨‹åºç»“æŸ")
    
    except KeyboardInterrupt:
        logger.info("ç¨‹åºå·²æ‰‹åŠ¨ç»ˆæ­¢")
    except Exception as e:
        logger.error(f"ä¸»å¾ªç¯å¼‚å¸¸: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logger.add(
        "attendance_monitor.log", 
        rotation="10 MB", 
        retention="7 days", 
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {message}",
        level="INFO"
    )
    
    logger.info("======= è€ƒå‹¤ç›‘æ§ç¨‹åºå¯åŠ¨ =======")
    logger.info(f"ç›‘æ§äººå‘˜: {', '.join(names)}")
    logger.info(f"å·¥ä½œæ—¶é•¿é˜ˆå€¼: {WORK_DURATION_THRESHOLD}å°æ—¶")
    start_time = time.time()
    
    main()
    
    duration = time.time() - start_time
    logger.info(f"ç¨‹åºè¿è¡Œå®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
    logger.info("=" * 50)
