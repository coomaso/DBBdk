import requests
import json
import os
import time
from loguru import logger
from datetime import datetime, timedelta
from collections import defaultdict

# é…ç½®å‚æ•°
max_attempts = 10
# æ”¯æŒå¤šä¸ªäººå‘˜æŸ¥è¯¢
names = ["ä»£ç¢§æ³¢", "å‘¨æ°‘é”‹"]
BASE_url = "http://106.15.60.27:33333"
login_url = "http://106.15.60.27:33333/laboratt/attendance/page"
wexinqq_url = os.environ["QYWX_URL"]

# ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯é•¿åº¦é™åˆ¶ (4096å­—ç¬¦)
MAX_MESSAGE_LENGTH = 2000  # ä¿ç•™ä¸€äº›ç©ºé—´

# å·¥ä½œæ—¶é•¿é˜ˆå€¼ (å°æ—¶)
WORK_DURATION_THRESHOLD = 4

headers = {
    # "Host": "zhcjsmz.sanxiacloud.com",
    "Connection": "keep-alive",
    "sec-ch-ua": '"Not.A/Brand";v="8", "Chromium";v="114"',
    "Accept": "*/*",
    "Content-Type": "application/json;charset=UTF-8",
    "sec-ch-ua-mobile": "?0",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.5735.289 Safari/537.36",
    "sec-ch-ua-platform": '"Windows"',
    "Origin": "http://106.15.60.27:33333",
    "Referer": "http://106.15.60.27:33333/login/",
    "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8,vi;q=0.7",
    "Accept-Encoding": "gzip, deflate",
    "Authorization": "Basic cGlnOnBpZw=="
}

# ================== é€šçŸ¥å‘é€ ==================
def send_wexinqq_md(content):
    """å‘é€Markdownæ¶ˆæ¯åˆ°ä¼ä¸šå¾®ä¿¡"""
    try:
        # æ£€æŸ¥å†…å®¹é•¿åº¦
        if len(content) > MAX_MESSAGE_LENGTH:
            logger.warning(f"æ¶ˆæ¯é•¿åº¦ {len(content)} è¶…è¿‡é™åˆ¶ ({MAX_MESSAGE_LENGTH})ï¼Œå°†è¢«æˆªæ–­")
            content = content[:MAX_MESSAGE_LENGTH] + "\n\n...ï¼ˆå†…å®¹è¿‡é•¿è¢«æˆªæ–­ï¼‰"
        
        response = requests.post(
            wexinqq_url,
            json={'msgtype': 'markdown', 'markdown': {'content': content}},
            timeout=10
        )
        result = response.json()
        if result.get('errcode') == 0:
            logger.success("ä¼ä¸šå¾®ä¿¡é€šçŸ¥å‘é€æˆåŠŸ")
            return True
        else:
            logger.error(f"ä¼ä¸šå¾®ä¿¡é€šçŸ¥å‘é€å¤±è´¥: {result}")
            return False
    except Exception as e:
        logger.error(f"å‘é€ä¼ä¸šå¾®ä¿¡é€šçŸ¥æ—¶å‡ºé”™: {str(e)}")
        return False

def send_paginated_messages(messages):
    """åˆ†é¡µå‘é€æ¶ˆæ¯ï¼Œé¿å…è¶…è¿‡é•¿åº¦é™åˆ¶"""
    if not messages:
        return False
    
    # è®¡ç®—æ¯æ¡æ¶ˆæ¯çš„å¹³å‡é•¿åº¦
    total_length = sum(len(msg) for msg in messages)
    if messages:
        avg_length = total_length / len(messages)
    else:
        avg_length = 0
    
    # è®¡ç®—æ¯æ‰¹å¯ä»¥åŒ…å«å¤šå°‘æ¡æ¶ˆæ¯
    if avg_length > 0:
        batch_size = max(1, int(MAX_MESSAGE_LENGTH / avg_length))
    else:
        batch_size = 5  # é»˜è®¤æ¯æ‰¹5æ¡
    
    logger.info(f"å¹³å‡æ¯æ¡æ¶ˆæ¯é•¿åº¦: {avg_length:.0f}, æ¯æ‰¹å‘é€ {batch_size} æ¡è®°å½•")
    
    # åˆ†æ‰¹å‘é€
    all_success = True
    for i in range(0, len(messages), batch_size):
        batch = messages[i:i + batch_size]
        content = "\n\n".join(batch)
        
        # æ·»åŠ åˆ†é¡µä¿¡æ¯
        total_pages = (len(messages) + batch_size - 1) // batch_size
        current_page = i // batch_size + 1
        page_info = f"# ğŸ“‹ è€ƒå‹¤è®°å½•é€šçŸ¥ ({current_page}/{total_pages})\n\n"
        
        # å‘é€å½“å‰æ‰¹æ¬¡
        logger.info(f"å‘é€ç¬¬ {current_page}/{total_pages} æ‰¹æ¶ˆæ¯ ({len(batch)}æ¡è®°å½•)")
        if not send_wexinqq_md(page_info + content):
            all_success = False
            logger.error(f"ç¬¬ {current_page} æ‰¹æ¶ˆæ¯å‘é€å¤±è´¥")
        
        # æ‰¹æ¬¡é—´å»¶è¿Ÿ
        time.sleep(1)
    
    return all_success

# ================== æ•°æ®ç›‘æ§ ==================
def load_existing_ids():
    """åŠ è½½å·²è®°å½•çš„IDé›†åˆ"""
    try:
        if os.path.exists('ids.json'):
            with open('ids.json') as f:
                ids = json.load(f)
                logger.info(f"æˆåŠŸåŠ è½½ {len(ids)} æ¡å†å²è®°å½•ID")
                return set(ids)
        else:
            logger.warning("æœªæ‰¾åˆ°ids.jsonæ–‡ä»¶ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
            return set()
    except json.JSONDecodeError:
        logger.error("ids.jsonæ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œå°†é‡æ–°åˆ›å»º")
        return set()

def save_new_ids(ids):
    """ä¿å­˜æ–°çš„IDé›†åˆ"""
    try:
        with open('ids.json', 'w') as f:
            json.dump(list(ids), f)
        logger.info(f"æˆåŠŸä¿å­˜{len(ids)}æ¡è®°å½•IDåˆ°ids.json")
    except Exception as e:
        logger.error(f"ä¿å­˜IDé›†åˆå¤±è´¥: {str(e)}")

def fetch_records_for_name(name):
    """è·å–å•ä¸ªåå­—çš„æ‰€æœ‰åˆ†é¡µæ•°æ®"""
    records = []
    page = 1
    while True:
        try:
            # æ„å»ºæŸ¥è¯¢URL
            url = f"{login_url}?page={page}&limit=100&name={name}&orderByField=verifyTime&isAsc=false"
            logger.debug(f"è¯·æ±‚URL: {url}")
            
            response = requests.get(url, headers=headers, timeout=15)
            logger.info(f"è¯·æ±‚ {name} çš„è€ƒå‹¤è®°å½•, é¡µç : {page}, çŠ¶æ€ç : {response.status_code}")
            
            if response.status_code != 200:
                logger.error(f"è¯·æ±‚å¤±è´¥: {response.text}")
                break

            json_data = response.json()

            # å…¼å®¹å¤„ç†ä¸åŒç»“æ„
            if "data" in json_data and isinstance(json_data["data"], dict):
                page_records = json_data["data"].get("records", [])
            elif "records" in json_data and isinstance(json_data["records"], list):
                page_records = json_data["records"]
            else:
                logger.error(f"å“åº”æ ¼å¼å¼‚å¸¸: {json_data}")
                break

            if not page_records:
                logger.info(f"åå­— {name} çš„ç¬¬ {page} é¡µæ²¡æœ‰æ›´å¤šè®°å½•äº†")
                break

            records.extend(page_records)
            logger.info(f"ç¬¬ {page} é¡µè·å–åˆ° {len(page_records)} æ¡è®°å½•")
            page += 1
            
            # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(0.5)
            
        except Exception as e:
            logger.error(f"è·å–æ•°æ®å¤±è´¥: {e}")
            break
    
    logger.info(f"æ€»å…±è·å–åˆ° {len(records)} æ¡ {name} çš„è®°å½•")
    return records

def fetch_all_records():
    """è·å–æ‰€æœ‰åå­—çš„æ‰€æœ‰è®°å½•"""
    all_records = []
    for name in names:
        logger.info(f"å¼€å§‹æŸ¥è¯¢ {name} çš„è€ƒå‹¤è®°å½•")
        records = fetch_records_for_name(name)
        all_records.extend(records)
        logger.success(f"æŸ¥è¯¢åˆ° {name} çš„ {len(records)} æ¡è®°å½•")
    
    # æŒ‰æ—¶é—´æ’åº (ä»æ–°åˆ°æ—§)
    all_records.sort(key=lambda x: x.get('verifyTime', 0), reverse=True)
    return all_records

def calculate_work_duration(record, grouped_records):
    """è®¡ç®—å·¥ä½œæ—¶é•¿ï¼ˆä»…é€‚ç”¨äºç¦»å¼€è®°å½•ï¼‰"""
    try:
        # è·å–è®°å½•æ—¶é—´
        timestamp = record.get('verifyTime', 0) / 1000
        if not timestamp:
            return None
        
        # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
        utc_time = datetime.utcfromtimestamp(timestamp)
        beijing_time = utc_time + timedelta(hours=8)
        date_key = beijing_time.date().isoformat()
        
        # è·å–å§“å
        name = record.get('name', 'æœªçŸ¥')
        
        # è·å–å½“å¤©æ‰€æœ‰è¿›å…¥è®°å½•
        in_records = grouped_records.get((name, date_key), {}).get('in', [])
        
        # å¦‚æœæ²¡æœ‰è¿›å…¥è®°å½•ï¼Œæ— æ³•è®¡ç®—æ—¶é•¿
        if not in_records:
            return None
        
        # æ‰¾åˆ°æœ€æ—©çš„è¿›å…¥è®°å½•
        earliest_in = min(in_records, key=lambda x: x['beijing_time'])
        
        # è®¡ç®—å·¥ä½œæ—¶é•¿ï¼ˆå°æ—¶ï¼‰
        work_duration = (beijing_time - earliest_in['beijing_time']).total_seconds() / 3600
        return work_duration
    
    except Exception as e:
        logger.error(f"è®¡ç®—å·¥ä½œæ—¶é•¿å¤±è´¥: {str(e)}")
        return None

def check_new_records():
    """æ£€æŸ¥æ–°è®°å½•å¹¶å‘é€é€šçŸ¥"""
    try:
        existing_ids = load_existing_ids()
        logger.info(f"å·²åŠ è½½ {len(existing_ids)} æ¡å†å²è®°å½•ID")
        
        current_ids = set()
        new_records = []
        
        records = fetch_all_records()
        logger.info(f"æ€»å…±æŸ¥è¯¢åˆ° {len(records)} æ¡è®°å½•")
        
        # æ£€æŸ¥æ–°è®°å½•
        for record in records:
            record_id = record.get('id')
            if not record_id:
                continue
                
            current_ids.add(record_id)
            if record_id not in existing_ids:
                new_records.append(record)
        
        if new_records:
            logger.success(f"å‘ç° {len(new_records)} æ¡æ–°è®°å½•")
            
            # æŒ‰æ—¶é—´æ’åº (ä»æ—§åˆ°æ–°ï¼Œè¿™æ ·é€šçŸ¥ä¸­å…ˆæ˜¾ç¤ºæœ€æ—©çš„è®°å½•)
            new_records.sort(key=lambda x: x.get('verifyTime', 0))
            
            # æŒ‰å§“åå’Œæ—¥æœŸåˆ†ç»„è®°å½•ï¼ˆç”¨äºå·¥ä½œæ—¶é•¿è®¡ç®—ï¼‰
            grouped_records = defaultdict(lambda: defaultdict(list))
            for record in new_records:
                # æ·»åŠ åŒ—äº¬æ—¶é—´å­—æ®µ
                timestamp = record.get('verifyTime', 0) / 1000
                if timestamp:
                    utc_time = datetime.utcfromtimestamp(timestamp)
                    beijing_time = utc_time + timedelta(hours=8)
                    record['beijing_time'] = beijing_time
                    date_key = beijing_time.date().isoformat()
                    
                    # æŒ‰å§“åå’Œæ—¥æœŸåˆ†ç»„
                    key = (record.get('name', 'æœªçŸ¥'), date_key)
                    grouped_records[key][record.get('inOrOut', 'unknown')].append(record)
            
            messages = []
            warning_count = 0
            
            for r in new_records:
                # è·å–åŒ—äº¬æ—¶é—´ï¼ˆå·²åœ¨ä¸Šä¸€æ­¥æ·»åŠ ï¼‰
                beijing_time = r.get('beijing_time', None)
                if not beijing_time:
                    timestamp = r.get('verifyTime', 0) / 1000
                    if timestamp:
                        utc_time = datetime.utcfromtimestamp(timestamp)
                        beijing_time = utc_time + timedelta(hours=8)
                    else:
                        beijing_time = "æœªçŸ¥æ—¶é—´"
                
                # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
                time_str = beijing_time.strftime('%Y-%m-%d %H:%M:%S') if isinstance(beijing_time, datetime) else beijing_time
                
                # è·å–é¡¹ç›®åç§°ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼
                project_name = r.get('engName', 'æœªçŸ¥é¡¹ç›®')
                if not project_name or project_name == 'null':
                    project_name = r.get('projectName', 'æœªçŸ¥é¡¹ç›®')
                    
                # è·å–è¿›å‡ºçŠ¶æ€
                status = r.get('inOrOut', 'æœªçŸ¥')
                status_text = "è¿›å…¥" if status == 'in' else "ç¦»å¼€"
                status_color = "info" if status == 'in' else "warning"
                
                # åˆ›å»ºæ¶ˆæ¯
                message = (
                    f"## ğŸ‰ æ–°è€ƒå‹¤è®°å½•\n"
                    f"> **é¡¹ç›®åç§°**: {project_name}\n"
                    f"> **å§“å**: {r.get('name', 'æœªçŸ¥')}\n"
                    f"> **å²—ä½**: {r.get('jobName', 'æœªçŸ¥')}\n"
                    f"> **æ—¶é—´**: <font color=\"info\">{time_str}</font>\n"
                    f"> **çŠ¶æ€**: <font color=\"{status_color}\">{status_text}</font>\n"
                )
                
                # å¦‚æœæ˜¯ç¦»å¼€è®°å½•ï¼Œæ£€æŸ¥å·¥ä½œæ—¶é•¿
                if status == 'out' and isinstance(beijing_time, datetime):
                    work_duration = calculate_work_duration(r, grouped_records)
                    if work_duration is not None:
                        # æ·»åŠ å·¥ä½œæ—¶é•¿ä¿¡æ¯
                        message += f"> **å·¥ä½œæ—¶é•¿**: {work_duration:.2f}å°æ—¶\n"
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸è¶³4å°æ—¶
                        if work_duration < WORK_DURATION_THRESHOLD:
                            warning_count += 1
                            message += f"> **è­¦å‘Š**: <font color=\"warning\">å·¥ä½œæ—¶é•¿ä¸è¶³{WORK_DURATION_THRESHOLD}å°æ—¶ï¼</font>\n"
                
                messages.append(message)
            
            # æ·»åŠ æ€»æ ‡é¢˜
            summary = f"# ğŸ“¢ å‘ç° {len(new_records)} æ¡æ–°è€ƒå‹¤è®°å½•\n"
            if warning_count > 0:
                summary += f"## âš ï¸ å…¶ä¸­æœ‰ {warning_count} æ¡å·¥ä½œæ—¶é•¿ä¸è¶³{WORK_DURATION_THRESHOLD}å°æ—¶\n\n"
            
            # åˆ†é¡µå‘é€æ¶ˆæ¯
            message_list = [summary] + messages
            send_success = send_paginated_messages(message_list)
            
            # å‘é€å®Œæˆæ¶ˆæ¯
            if send_success:
                send_wexinqq_md(f"# âœ… è€ƒå‹¤é€šçŸ¥å·²å®Œæˆ\nå…±å¤„ç† {len(new_records)} æ¡æ–°è®°å½•")
            
            # é€šçŸ¥å‘é€æˆåŠŸåæ‰ä¿å­˜ID
            if send_success:
                save_new_ids(existing_ids.union(current_ids))
                return True
            else:
                logger.error("é€šçŸ¥å‘é€å¤±è´¥ï¼Œä¸æ›´æ–°è®°å½•ID")
                return False
        else:
            logger.info("æœªå‘ç°æ–°è®°å½•")
            return False
            
    except Exception as e:
        logger.error(f"æ£€æŸ¥æ–°è®°å½•æ—¶å‡ºé”™: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False

# ================== ä¸»å¾ªç¯ ==================
def main():
    try:
        # æ•°æ®æ£€æŸ¥
        if check_new_records():
            logger.success("å‘ç°æ–°è®°å½•å¹¶æˆåŠŸé€šçŸ¥")
        else:
            logger.info("æœªå‘ç°æ–°è®°å½•")
        
        # ä¸€æ¬¡æ€§æ‰§è¡Œåç»“æŸç¨‹åºï¼Œä¸å†å¾ªç¯
        logger.info("æ‰§è¡Œå®Œæ¯•ï¼Œç¨‹åºç»“æŸ")
    
    except KeyboardInterrupt:
        logger.info("ç¨‹åºå·²æ‰‹åŠ¨ç»ˆæ­¢")
    except Exception as e:
        logger.error(f"ä¸»å¾ªç¯å¼‚å¸¸: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logger.add(
        "attendance_monitor.log", 
        rotation="10 MB", 
        retention="7 days", 
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {message}",
        level="INFO"
    )
    
    logger.info("======= è€ƒå‹¤ç›‘æ§ç¨‹åºå¯åŠ¨ =======")
    logger.info(f"ç›‘æ§äººå‘˜: {', '.join(names)}")
    logger.info(f"å·¥ä½œæ—¶é•¿é˜ˆå€¼: {WORK_DURATION_THRESHOLD}å°æ—¶")
    start_time = time.time()
    
    main()
    
    duration = time.time() - start_time
    logger.info(f"ç¨‹åºè¿è¡Œå®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
    logger.info("=" * 50)
